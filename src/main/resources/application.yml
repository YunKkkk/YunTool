server:
  port: 8080
spring:
  profiles:
    active: dev
  cloud:
    ai:
      tongyi:
        api-key: sk-
        chat:
          options:
            model: deepseek-r1
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: deepseek-r1
          temperature: 0.7
        enabled: true